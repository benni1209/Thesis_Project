---
title: "Missing at Random (MAR) - Modified with Selection Scenarios"
author: "Benedikt Sojka | s4089448"
date: "2025-07-17"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(dplyr)
library(knitr)
library(sampling)  # Added for UPrandomsystematic
```

# 1. Core Functions

## 1.1 Selection Probability Patterns

```{r}
# Function to generate different selection probability patterns
generate_selection_probs <- function(scenario, base_prob = 0.0075) {
  
  scenarios <- list(
    # Scenario 1: Linear decreasing (e.g., lower income groups more accessible)
    linear_decreasing = function() {
      probs <- seq(1.8, 0.3, length.out = 6)
      probs * base_prob
    },
    
    # Scenario 2: U-shaped (e.g., extreme cases more likely to self-select)
    u_shaped = function() {
      probs <- c(4, 1, 0.5, 0.5, 1, 4)
      probs * base_prob
    },
    
    # Scenario 3: Step function (e.g., threshold effect at X=4)
    step_function = function() {
      probs <- c(2, 2, 2, 0.5, 0.5, 0.5)
      probs * base_prob
    },
    
    # Scenario 4: Extreme bias (very strong selection on high X values)
    extreme_bias = function() {
      probs <- c(0.1, 0.2, 0.3, 0.5, 1.0, 4.0)
      probs * base_prob
    },
    
    # Scenario 5: Linear decreasing - moderate ratio (lower ratio than Scenario 1)
    linear_decreasing_moderate = function() {
      probs <- seq(1.2, 0.4, length.out = 6)  # Ratio = 3
      probs * base_prob
    },
    
    # Scenario 6: Linear decreasing - extreme ratio (higher ratio than Scenario 1)
    linear_decreasing_extreme = function() {
      probs <- seq(3.0, 0.25, length.out = 6)  # Ratio = 12
      probs * base_prob
    }
  )
  
  return(scenarios[[scenario]]())
}
```

## 1.2 Population Generation Function

```{r}
generate_population <- function(pop_size = 1000000, seed = 123) {
  set.seed(seed)
  
  # Create population with X variable
  population <- data.frame(
    id = 1:pop_size,
    X = sample(1:6, pop_size, replace = TRUE, 
               prob = c(0.15, 0.15, 0.20, 0.20, 0.15, 0.15))
  )
  
  # Generate Y based on X
  y_probs <- matrix(c(
    0.6, 0.2, 0.2,  # X=1
    0.6, 0.2, 0.2,  # X=2
    0.4, 0.3, 0.3,  # X=3
    0.3, 0.3, 0.4,  # X=4
    0.2, 0.3, 0.5,  # X=5
    0.1, 0.3, 0.6   # X=6
  ), nrow = 6, byrow = TRUE)
  
  population$Y <- apply(population, 1, function(row) {
    sample(0:2, 1, prob = y_probs[row["X"], ])
  })
  
  # Generate Z based on X with correlation to Y
  z_base_probs <- matrix(c(
    0.15, 0.15, 0.70,  # X=1
    0.15, 0.25, 0.60,  # X=2
    1/3,  1/3,  1/3,   # X=3
    1/3,  1/3,  1/3,   # X=4
    0.60, 0.25, 0.15,  # X=5
    0.70, 0.15, 0.15   # X=6
  ), nrow = 6, byrow = TRUE)
  
  population$Z <- sapply(1:pop_size, function(i) {
    z_probs <- z_base_probs[population$X[i], ]
    
    # Add correlation with Y
    if (population$Y[i] == 0) {
      z_probs <- z_probs + c(0.20, -0.10, -0.10)
    } else if (population$Y[i] == 1) {
      z_probs <- z_probs + c(-0.10, 0.20, -0.10)
    } else {
      z_probs <- z_probs + c(-0.10, -0.10, 0.20)
    }
    
    z_probs <- pmax(z_probs, 0)
    z_probs <- z_probs / sum(z_probs)
    sample(0:2, 1, prob = z_probs)
  })
  
  return(population)
}
```

## 1.3 Sample Drawing Function

```{r}
draw_samples <- function(
  population,
  sample_A_size = 150000,
  sample_B_size = 150000,
  sample_C_size = 7500,
  selection_scenario = "linear_decreasing",
  seed = 123
) {
  set.seed(seed)
  
  # Draw Sample C using UPrandomsystematic with selection probabilities
  sel_probs_by_x <- generate_selection_probs(selection_scenario)
  
  # Create inclusion probabilities for each unit based on their X value
  inclusion_probs <- sel_probs_by_x[population$X]
  
  # Normalize to sum to sample_C_size (required for UPrandomsystematic)
  inclusion_probs <- inclusion_probs * sample_C_size / sum(inclusion_probs)
  
  # Use UPrandomsystematic for unequal probability sampling
  sample_C_selected <- UPrandomsystematic(inclusion_probs)
  sample_C_indices <- which(sample_C_selected == 1)
  
  sample_C <- population[sample_C_indices, ]
  
  # Draw samples A and B from remaining population
  pop_remaining <- population[-sample_C_indices, ]
  sample_A_indices <- sample(1:nrow(pop_remaining), sample_A_size, FALSE)
  sample_A <- pop_remaining[sample_A_indices, c("id", "X", "Y")]
  
  pop_remaining_B <- pop_remaining[-sample_A_indices, ]
  sample_B_indices <- sample(1:nrow(pop_remaining_B), sample_B_size, FALSE)
  sample_B <- pop_remaining_B[sample_B_indices, c("id", "X", "Z")]
  
  return(list(
    population = population,
    sample_A = sample_A,
    sample_B = sample_B,
    sample_C = sample_C,
    selection_scenario = selection_scenario
  ))
}
```

## 1.4 Calibration Functions

```{r}
# Weight adjustment functions
adjust_weights <- function(data, weights, var_name, target) {
  wt_dist <- tapply(weights, data[[var_name]], sum)
  wt_dist <- wt_dist / sum(weights)
  new_weights <- weights
  
  for (cat in names(target)) {
    idx <- which(data[[var_name]] == as.numeric(cat))
    if (length(idx) > 0 && !is.na(wt_dist[cat]) && wt_dist[cat] > 0) {
      adjustment <- target[cat] / wt_dist[cat]
      new_weights[idx] <- weights[idx] * adjustment
    }
  }
  return(new_weights)
}

adjust_weights_2d <- function(data, weights, var1_name, var2_name, target) {
  cross_table <- xtabs(weights ~ data[[var1_name]] + data[[var2_name]])
  wt_dist <- prop.table(cross_table)
  new_weights <- weights
  
  for (i in rownames(target)) {
    for (j in colnames(target)) {
      idx <- which(data[[var1_name]] == as.numeric(i) & 
                   data[[var2_name]] == as.numeric(j))
      if (length(idx) > 0) {
        current <- if(i %in% rownames(wt_dist) && j %in% colnames(wt_dist)) 
          wt_dist[i, j] else 0
        if (!is.na(current) && current > 0) {
          adjustment <- target[i, j] / current
          new_weights[idx] <- weights[idx] * adjustment
        }
      }
    }
  }
  return(new_weights)
}

# Calibration function
calibrate_sample_C <- function(data_list) {
  sample_C <- data_list$sample_C
  
  # Initialize weights
  sample_C$weight_full <- 1
  sample_C$weight_X <- 1
  
  # Define targets
  x_target <- prop.table(table(data_list$population$X))
  xy_target <- prop.table(table(data_list$sample_A$X, data_list$sample_A$Y))
  xz_target <- prop.table(table(data_list$sample_B$X, data_list$sample_B$Z))
  
  # Full calibration (X, XY, XZ)
  for (iter in 1:50) {
    old_weights <- sample_C$weight_full
    sample_C$weight_full <- adjust_weights_2d(sample_C, sample_C$weight_full, "X", "Y", xy_target)
    sample_C$weight_full <- adjust_weights_2d(sample_C, sample_C$weight_full, "X", "Z", xz_target)
    sample_C$weight_full <- adjust_weights(sample_C, sample_C$weight_full, "X", x_target)
    if (max(abs(sample_C$weight_full - old_weights)) < 1e-6) break
  }
  
  # X-only calibration
  sample_C$weight_X <- adjust_weights(sample_C, sample_C$weight_X, "X", x_target)
  
  # Normalize weights
  sample_C$weight_full <- sample_C$weight_full * nrow(sample_C) / sum(sample_C$weight_full)
  sample_C$weight_X <- sample_C$weight_X * nrow(sample_C) / sum(sample_C$weight_X)
  
  data_list$sample_C <- sample_C
  return(data_list)
}
```

## 1.5 EM Algorithm

```{r}
em_multinomial <- function(fully_observed, var1_only, var2_only, 
                          max_iterations = 200, tolerance = 1e-6) {
  imputed_table <- fully_observed
  epsilon <- 1e-10
  
  for (iter in 1:max_iterations) {
    old_table <- imputed_table
    row_sums <- rowSums(imputed_table) + epsilon
    col_sums <- colSums(imputed_table) + epsilon
    new_table <- fully_observed
    
    for (i in 1:nrow(imputed_table)) {
      for (j in 1:ncol(imputed_table)) {
        row_prop <- if(row_sums[i] > epsilon) imputed_table[i,j]/row_sums[i] else 0
        col_prop <- if(col_sums[j] > epsilon) imputed_table[i,j]/col_sums[j] else 0
        
        var1_imputed <- row_prop * var1_only[i]
        var2_imputed <- col_prop * var2_only[j]
        
        new_table[i,j] <- new_table[i,j] + var1_imputed + var2_imputed
      }
    }
    
    imputed_table <- new_table
    if (max(abs((imputed_table - old_table)/(old_table + epsilon))) < tolerance) break
  }
  
  return(imputed_table)
}
```

# 2. Bootstrap Data Collection

## 2.1 Method Implementation Function

```{r}
apply_all_methods <- function(data_list) {
  sample_C <- data_list$sample_C
  sample_A <- data_list$sample_A
  sample_B <- data_list$sample_B
  
  # Store all distributions
  distributions <- list()
  
  # True Y-Z distribution from population
  distributions$true <- prop.table(table(data_list$population$Y, data_list$population$Z))
  
  # Method 1: Raw Sample C
  distributions$raw <- prop.table(table(sample_C$Y, sample_C$Z))
  
  # Method 2: Sample C with full calibration (X, XY, XZ)
  full_cal_table <- matrix(0, 3, 3, dimnames = list(0:2, 0:2))
  for (y in 0:2) {
    for (z in 0:2) {
      idx <- sample_C$Y == y & sample_C$Z == z
      if (sum(idx) > 0) {
        full_cal_table[as.character(y), as.character(z)] <- sum(sample_C$weight_full[idx])
      }
    }
  }
  distributions$calibrated_full <- prop.table(full_cal_table)
  
  # Method 3: Sample C with X-only calibration
  x_cal_table <- matrix(0, 3, 3, dimnames = list(0:2, 0:2))
  for (y in 0:2) {
    for (z in 0:2) {
      idx <- sample_C$Y == y & sample_C$Z == z
      if (sum(idx) > 0) {
        x_cal_table[as.character(y), as.character(z)] <- sum(sample_C$weight_X[idx])
      }
    }
  }
  distributions$calibrated_x <- prop.table(x_cal_table)
  
  # Method 4: EM with Raw Sample C
  var1_only <- as.numeric(table(sample_A$Y))
  var2_only <- as.numeric(table(sample_B$Z))
  raw_table <- table(sample_C$Y, sample_C$Z)
  em_raw_table <- em_multinomial(raw_table, var1_only, var2_only)
  distributions$em_raw <- prop.table(em_raw_table)
  
  # Method 5: EM with X-calibrated Sample C
  em_x_table <- em_multinomial(x_cal_table, var1_only, var2_only)
  distributions$em_calibrated <- prop.table(em_x_table)
  
  return(distributions)
}
```

## 2.2 Bootstrap Analysis Function

```{r}
run_bootstrap <- function(pop_size = 1000000, 
                         n_bootstrap = 100, 
                         sample_sizes = list(A = 150000, B = 150000, C = 7500),
                         scenarios = c("linear_decreasing", "u_shaped", "step_function", 
                                     "extreme_bias", "linear_decreasing_moderate", 
                                     "linear_decreasing_extreme"),
                         seed = 123) {
  
  # Generate population once
  cat("Generating population...\n")
  population <- generate_population(pop_size = pop_size, seed = seed)
  
  # Initialize storage for all bootstrap results
  bootstrap_data <- list()
  
  # Run bootstrap for each scenario
  for (scenario in scenarios) {
    cat("\nRunning bootstrap for scenario:", scenario, "\n")
    pb <- txtProgressBar(min = 0, max = n_bootstrap, style = 3)
    
    scenario_results <- list()
    
    for (b in 1:n_bootstrap) {
      # Draw new samples with fixed population
      data_list <- draw_samples(
        population = population,
        sample_A_size = sample_sizes$A,
        sample_B_size = sample_sizes$B,
        sample_C_size = sample_sizes$C,
        selection_scenario = scenario,
        seed = seed + b * 1000 + which(scenarios == scenario) * 100000
      )
      
      # Calibrate Sample C
      data_list <- calibrate_sample_C(data_list)
      
      # Apply all methods and get distributions
      distributions <- apply_all_methods(data_list)
      
      # Store complete results for this iteration
      scenario_results[[b]] <- list(
        distributions = distributions,
        sample_info = list(
          sample_C_size = nrow(data_list$sample_C),
          sample_A_size = nrow(data_list$sample_A),
          sample_B_size = nrow(data_list$sample_B)
        )
      )
      
      setTxtProgressBar(pb, b)
    }
    close(pb)
    
    bootstrap_data[[scenario]] <- scenario_results
  }
  
  # Return complete bootstrap data including population
  return(list(
    data = bootstrap_data,
    population = population,
    n_bootstrap = n_bootstrap,
    sample_sizes = sample_sizes,
    scenarios = scenarios,
    methods = setdiff(names(bootstrap_data[[1]][[1]]$distributions), "true")
  ))
}
```

# 3. Run Bootstrap and Save Results

```{r}
# Define scenarios to analyze
scenarios_to_run <- c("linear_decreasing", "u_shaped", "step_function", 
                     "extreme_bias", "linear_decreasing_moderate", 
                     "linear_decreasing_extreme")

# Run bootstrap analysis
cat("Starting bootstrap analysis...\n\n")
bootstrap_results <- run_bootstrap(
  pop_size = 1000000,
  n_bootstrap = 1000,  # Set to desired number of iterations
  sample_sizes = list(A = 150000, B = 150000, C = 7500),
  scenarios = scenarios_to_run,
  seed = 123
)

# Save results
cat("\nSaving bootstrap results...\n")
saveRDS(bootstrap_results, "bootstrap_results_MAR_scenarios.rds")
cat("Bootstrap results saved to 'bootstrap_results_MAR_scenarios.rds'\n")

# Display completion message
cat("\nBootstrap data generation complete!\n")
cat("Number of iterations:", bootstrap_results$n_bootstrap, "\n")
cat("Scenarios analyzed:", paste(bootstrap_results$scenarios, collapse = ", "), "\n")
cat("Methods included:", paste(bootstrap_results$methods, collapse = ", "), "\n")
```

# 4. Quick Summary of Results Structure

```{r}
# Display structure of saved data
cat("\nStructure of saved results:\n")
cat("- Population size:", nrow(bootstrap_results$population), "\n")
cat("- Number of scenarios:", length(bootstrap_results$scenarios), "\n")
cat("- Bootstrap iterations per scenario:", bootstrap_results$n_bootstrap, "\n")
cat("- Total bootstrap runs:", length(bootstrap_results$scenarios) * bootstrap_results$n_bootstrap, "\n")
```