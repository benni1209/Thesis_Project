---
title: "Missing at Random (MAR) Analysis"
author: "Benedikt Sojka | s4089448"
date: "2025-07-17"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(dplyr)
library(knitr)
library(ggplot2)
library(tidyr)
library(gridExtra)
```

# 1. Load Bootstrap Results

```{r}
cat("Loading bootstrap results...\n")
bootstrap_results <- readRDS("bootstrap_results_MAR_scenarios(1000).rds")

cat("\nBootstrap results loaded successfully!\n")
cat("Number of bootstrap iterations per scenario:", bootstrap_results$n_bootstrap, "\n")
cat("Scenarios analyzed:", paste(bootstrap_results$scenarios, collapse = ", "), "\n")
cat("Methods available:", paste(bootstrap_results$methods, collapse = ", "), "\n")
```

# 2. Measurement Functions

## 2.1 Basic Measures

```{r}
calculate_total_abs_diff <- function(estimated, true) {
  sum(abs(estimated - true))
}

calculate_max_abs_error <- function(estimated, true) {
  max(abs(estimated - true))
}

calculate_swc_bias <- function(estimated, true) {
  abs_diffs <- abs(estimated - true)
  worst_cell_idx <- which.max(abs_diffs)
  signed_diff <- (estimated - true)[worst_cell_idx]
  return(signed_diff)
}

calculate_rmse <- function(estimated, true) {
  sqrt(mean((estimated - true)^2))
}

calculate_cramers_v <- function(dist_matrix) {
  N <- 10000
  table <- round(dist_matrix * N)
  chi2_test <- suppressWarnings(chisq.test(table))
  chi2 <- chi2_test$statistic
  n <- sum(table)
  r <- nrow(table)
  c <- ncol(table)
  cramers_v <- sqrt(chi2 / (n * (min(r, c) - 1)))
  return(as.numeric(cramers_v))
}
```

## 2.2 Summary Functions

```{r}
calculate_measures <- function(estimated, true, baseline = NULL) {
  measures <- list(
    total_abs_diff = calculate_total_abs_diff(estimated, true),
    max_abs_error = calculate_max_abs_error(estimated, true),
    rmse = calculate_rmse(estimated, true),
    cramers_v = calculate_cramers_v(estimated),
    cramers_v_true = calculate_cramers_v(true),
    cramers_v_error = abs(calculate_cramers_v(estimated) - calculate_cramers_v(true)),
    swc_bias = calculate_swc_bias(estimated, true)
  )
  
  if (!is.null(baseline)) {
    baseline_measures <- list(
      total_abs_diff = calculate_total_abs_diff(baseline, true),
      max_abs_error = calculate_max_abs_error(baseline, true),
      rmse = calculate_rmse(baseline, true),
      cramers_v_error = abs(calculate_cramers_v(baseline) - calculate_cramers_v(true))
    )
    
    measures$rel_improvement_total_abs <- 
      (baseline_measures$total_abs_diff - measures$total_abs_diff) / 
      baseline_measures$total_abs_diff * 100
    
    measures$rel_improvement_max_abs <- 
      (baseline_measures$max_abs_error - measures$max_abs_error) / 
      baseline_measures$max_abs_error * 100
    
    measures$rel_improvement_rmse <- 
      (baseline_measures$rmse - measures$rmse) / 
      baseline_measures$rmse * 100
    
    measures$rel_improvement_cramers_v <- 
      (baseline_measures$cramers_v_error - measures$cramers_v_error) / 
      baseline_measures$cramers_v_error * 100
  }
  
  return(measures)
}
```

# 3. Analysis Functions for Multiple Scenarios

## 3.1 Extract Measures from Bootstrap Data with Scenarios

```{r}
extract_bootstrap_measures_scenarios <- function(bootstrap_results) {
  n_bootstrap <- bootstrap_results$n_bootstrap
  methods <- bootstrap_results$methods
  scenarios <- bootstrap_results$scenarios
  
  all_measures <- list()
  
  for (scenario in scenarios) {
    scenario_measures <- list()
    
    for (b in 1:n_bootstrap) {
      iter_data <- bootstrap_results$data[[scenario]][[b]]
      true_dist <- iter_data$distributions$true
      raw_dist <- iter_data$distributions$raw
      
      for (method in methods) {
        estimated_dist <- iter_data$distributions[[method]]
        measures <- calculate_measures(estimated_dist, true_dist, raw_dist)
        
        if (!method %in% names(scenario_measures)) {
          scenario_measures[[method]] <- list()
        }
        
        for (measure_name in names(measures)) {
          if (!measure_name %in% names(scenario_measures[[method]])) {
            scenario_measures[[method]][[measure_name]] <- numeric(n_bootstrap)
          }
          scenario_measures[[method]][[measure_name]][b] <- measures[[measure_name]]
        }
      }
    }
    
    all_measures[[scenario]] <- scenario_measures
  }
  
  return(all_measures)
}

cat("Extracting measures from bootstrap results...\n")
bootstrap_measures_scenarios <- extract_bootstrap_measures_scenarios(bootstrap_results)
```

## 3.2 Calculate Summary Statistics by Scenario

```{r}
calculate_summary_stats_by_scenario <- function(bootstrap_measures_scenarios) {
  scenarios <- names(bootstrap_measures_scenarios)
  summary_stats_all <- list()
  
  for (scenario in scenarios) {
    bootstrap_measures <- bootstrap_measures_scenarios[[scenario]]
    methods <- names(bootstrap_measures)
    measure_names <- names(bootstrap_measures[[1]])
    
    summary_stats <- list()
    
    for (method in methods) {
      method_summary <- list()
      
      for (measure in measure_names) {
        values <- bootstrap_measures[[method]][[measure]]
        
        method_summary[[measure]] <- list(
          mean = mean(values, na.rm = TRUE),
          median = median(values, na.rm = TRUE),
          sd = sd(values, na.rm = TRUE),
          ci_lower = quantile(values, 0.025, na.rm = TRUE),
          ci_upper = quantile(values, 0.975, na.rm = TRUE),
          min = min(values, na.rm = TRUE),
          max = max(values, na.rm = TRUE)
        )
      }
      
      summary_stats[[method]] <- method_summary
    }
    
    summary_stats_all[[scenario]] <- summary_stats
  }
  
  return(summary_stats_all)
}

cat("Calculating summary statistics by scenario...\n")
summary_stats_scenarios <- calculate_summary_stats_by_scenario(bootstrap_measures_scenarios)
```

## 3.3 Create Summary Tables

```{r}
create_measure_table <- function(summary_stats, scenario, measure_name) {
  methods <- names(summary_stats[[scenario]])
  
  method_labels <- c(
    "raw" = "Raw Sample C",
    "calibrated_x" = "Calibrated (X)",
    "calibrated_full" = "Calibrated (Full)",
    "em_raw" = "EM (Raw)",
    "em_calibrated" = "EM (Calibrated)"
  )
  
  table_df <- data.frame(
    Method = methods,
    Mean = sapply(methods, function(m) 
      summary_stats[[scenario]][[m]][[measure_name]]$mean),
    CI_Lower = sapply(methods, function(m) 
      summary_stats[[scenario]][[m]][[measure_name]]$ci_lower),
    CI_Upper = sapply(methods, function(m) 
      summary_stats[[scenario]][[m]][[measure_name]]$ci_upper),
    stringsAsFactors = FALSE
  )
  
  table_df$Method <- sapply(table_df$Method, function(m) 
    ifelse(m %in% names(method_labels), method_labels[m], m))
  
  table_df$`95% CI` <- sprintf("[%.4f, %.4f]", table_df$CI_Lower, table_df$CI_Upper)
  table_df <- table_df[, c("Method", "Mean", "95% CI")]
  
  return(table_df)
}

create_relative_improvement_table <- function(bootstrap_measures, scenario) {
  methods <- names(bootstrap_measures[[scenario]])
  methods <- methods[methods != "raw"]
  
  method_labels <- c(
    "calibrated_x" = "Calibrated (X)",
    "calibrated_full" = "Calibrated (Full)",
    "em_raw" = "EM (Raw)",
    "em_calibrated" = "EM (Calibrated)"
  )
  
  improvement_df <- data.frame(
    Method = methods,
    stringsAsFactors = FALSE
  )
  
  raw_mean <- mean(bootstrap_measures[[scenario]][["raw"]][["total_abs_diff"]])
  
  improvement_df$`Relative Improvement (%)` <- sapply(methods, function(m) {
    method_mean <- mean(bootstrap_measures[[scenario]][[m]][["total_abs_diff"]])
    improvement <- (raw_mean - method_mean) / raw_mean * 100
    return(improvement)
  })
  
  improvement_df$Method <- sapply(improvement_df$Method, function(m) 
    ifelse(m %in% names(method_labels), method_labels[m], m))
  
  return(improvement_df)
}

scenario_labels <- c(
  "linear_decreasing" = "Linear Decreasing",
  "u_shaped" = "U-Shaped",
  "step_function" = "Step Function",
  "extreme_bias" = "Extreme Bias",
  "linear_decreasing_moderate" = "Linear Decreasing (Moderate)",
  "linear_decreasing_extreme" = "Linear Decreasing (Extreme)"
)

cat("\n=== SUMMARY TABLES FOR ALL SCENARIOS ===\n\n")

for (scenario in bootstrap_results$scenarios) {
  scenario_label <- ifelse(scenario %in% names(scenario_labels),
                          scenario_labels[scenario],
                          scenario)
  
  cat("\n## Scenario:", scenario_label, "\n\n")
  
  cat("### Total Absolute Difference\n")
  total_abs_table <- create_measure_table(summary_stats_scenarios, scenario, "total_abs_diff")
  print(kable(total_abs_table, digits = 4, 
              caption = paste("Total Absolute Difference with 95% CI -", scenario_label)))
  
  cat("\n### Maximum Absolute Error\n")
  max_abs_table <- create_measure_table(summary_stats_scenarios, scenario, "max_abs_error")
  print(kable(max_abs_table, digits = 4, 
              caption = paste("Maximum Absolute Error with 95% CI -", scenario_label)))
  
  cat("\n### Single Worst Cell (SWC) Bias\n")
  swc_bias_table <- create_measure_table(summary_stats_scenarios, scenario, "swc_bias")
  print(kable(swc_bias_table, digits = 4, 
              caption = paste("SWC Bias (signed) with 95% CI -", scenario_label)))
  
  cat("\n### Relative Improvement vs Raw Sample C\n")
  improvement_table <- create_relative_improvement_table(bootstrap_measures_scenarios, scenario)
  print(kable(improvement_table, digits = 2, 
              caption = paste("Relative Improvement (%) based on Total Absolute Difference -", scenario_label)))
  
  cat("\n")
}
```

# 4. Visualizations

## 4.1 Method Comparison Within Scenarios

```{r, fig.width=11, fig.height=5}
plots_list <- list()

scenarios_to_include <- bootstrap_results$scenarios[1:4]

method_labels <- c(
  "raw" = "Raw Sample C",
  "calibrated_x" = "Calibrated (X)",
  "calibrated_full" = "Calibrated (Full)",
  "em_raw" = "EM (Raw)",
  "em_calibrated" = "EM (Calibrated X)"
)

method_order <- c("raw", "calibrated_x", "calibrated_full", "em_raw", "em_calibrated")

scenario_labels <- c(
  "linear_decreasing" = "Linear Decrease",
  "u_shaped" = "U-Shaped",
  "step_function" = "Step Function",
  "extreme_bias" = "Extreme Increase",
  "linear_decreasing_moderate" = "Linear Decreasing (Moderate)",
  "linear_decreasing_extreme" = "Linear Decreasing (Extreme)"
)

for (i in seq_along(scenarios_to_include)) {
  scenario <- scenarios_to_include[i]
  
  methods <- names(summary_stats_scenarios[[scenario]])
  
  scenario_label <- ifelse(scenario %in% names(scenario_labels),
                          scenario_labels[scenario],
                          scenario)
  
  plot_data <- data.frame(
    Method = factor(methods, levels = methods),
    Mean = sapply(methods, function(m) 
      summary_stats_scenarios[[scenario]][[m]][["total_abs_diff"]]$mean),
    CI_Lower = sapply(methods, function(m) 
      summary_stats_scenarios[[scenario]][[m]][["total_abs_diff"]]$ci_lower),
    CI_Upper = sapply(methods, function(m) 
      summary_stats_scenarios[[scenario]][[m]][["total_abs_diff"]]$ci_upper)
  )
  
  plot_data$Method <- factor(plot_data$Method, 
                            levels = method_order,
                            labels = method_labels[method_order])
  
  p <- ggplot(plot_data, aes(x = Method, y = Mean)) +
    geom_point(size = 3) +
    geom_errorbar(aes(ymin = CI_Lower, ymax = CI_Upper), width = 0.2) +
    labs(title = paste(scenario_label),
         y = "Total Absolute Difference") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  plots_list[[i]] <- p
}

grid.arrange(grobs = plots_list, ncol = 4)
```

## 4.2 Linear Decreasing Scenarios

```{r, fig.width=8, fig.height=4}
linear_scenarios <- c("linear_decreasing_moderate", "linear_decreasing", "linear_decreasing_extreme")

method_labels <- c(
  "raw" = "Raw Sample C",
  "calibrated_x" = "Calibrated (X)",
  "calibrated_full" = "Calibrated (Full)",
  "em_raw" = "EM (Raw)",
  "em_calibrated" = "EM (Calibrated X)"
)

linear_scenario_labels <- c(
  "linear_decreasing_moderate" = "Reduced Ratio",
  "linear_decreasing" = "Baseline",
  "linear_decreasing_extreme" = "Increased Ratio"
)

method_order_plot1 <- c("calibrated_full", "em_calibrated", "calibrated_x", "em_raw", "raw")

method_order_plot2 <- c("calibrated_full", "em_calibrated", "calibrated_x", "em_raw")

plot_data_abs_diff <- data.frame()

for (scenario in linear_scenarios) {
  for (method in method_order_plot1) {
    plot_data_abs_diff <- rbind(plot_data_abs_diff, data.frame(
      Scenario = scenario,
      Method = method,
      Mean = summary_stats_scenarios[[scenario]][[method]][["total_abs_diff"]]$mean,
      stringsAsFactors = FALSE
    ))
  }
}

plot_data_abs_diff$Scenario <- factor(plot_data_abs_diff$Scenario,
                                      levels = linear_scenarios,
                                      labels = linear_scenario_labels[linear_scenarios])
plot_data_abs_diff$Method <- factor(plot_data_abs_diff$Method,
                                   levels = method_order_plot1,
                                   labels = method_labels[method_order_plot1])

p_abs_diff <- ggplot(plot_data_abs_diff, aes(x = Scenario, y = Mean, fill = Method)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9)) +
  labs(x = "Scenario",
       y = "Total Absolute Difference",
       fill = "Method") +
  theme_minimal() +
  theme(legend.position = "right") +
  scale_fill_brewer(palette = "Set2")

print(p_abs_diff)

ggsave("linear_scenarios_abs_diff_barplot.pdf", 
       plot = p_abs_diff, 
       width = 8.5, 
       height = 4)

plot_data_rel_imp <- data.frame()

for (scenario in linear_scenarios) {
  raw_mean <- summary_stats_scenarios[[scenario]][["raw"]][["total_abs_diff"]]$mean
  
  for (method in method_order_plot2) {
    method_mean <- summary_stats_scenarios[[scenario]][[method]][["total_abs_diff"]]$mean
    rel_improvement <- (raw_mean - method_mean) / raw_mean * 100
    
    plot_data_rel_imp <- rbind(plot_data_rel_imp, data.frame(
      Scenario = scenario,
      Method = method,
      RelativeImprovement = rel_improvement,
      stringsAsFactors = FALSE
    ))
  }
}

plot_data_rel_imp$Scenario <- factor(plot_data_rel_imp$Scenario,
                                    levels = linear_scenarios,
                                    labels = linear_scenario_labels[linear_scenarios])
plot_data_rel_imp$Method <- factor(plot_data_rel_imp$Method,
                                  levels = method_order_plot2,
                                  labels = method_labels[method_order_plot2])

p_rel_imp <- ggplot(plot_data_rel_imp, aes(x = Scenario, y = RelativeImprovement, fill = Method)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
  labs(title = "Relative Improvement Compared to Raw Sample C",
       subtitle = "By Linear Decreasing Scenario",
       x = "Selection Bias Strength",
       y = "Relative Improvement (%)",
       fill = "Method") +
  theme_minimal() +
  theme(legend.position = "right") +
  scale_fill_brewer(palette = "Set2") +
  scale_y_continuous(labels = function(x) paste0(x, "%"))

print(p_rel_imp)
```

## 4.3 SWC Bias Visualization

```{r, fig.width=11, fig.height=5}
plots_swc_list <- list()

scenarios_to_include <- bootstrap_results$scenarios[1:4]

method_labels <- c(
  "raw" = "Raw Sample C",
  "calibrated_x" = "Calibrated (X)",
  "calibrated_full" = "Calibrated (Full)",
  "em_raw" = "EM (Raw)",
  "em_calibrated" = "EM (Calibrated X)"
)

method_order <- c("raw", "calibrated_x", "calibrated_full", "em_raw", "em_calibrated")

scenario_labels <- c(
  "linear_decreasing" = "Linear Decrease",
  "u_shaped" = "U-Shaped",
  "step_function" = "Step Function",
  "extreme_bias" = "Extreme Increase",
  "linear_decreasing_moderate" = "Linear Decreasing (Moderate)",
  "linear_decreasing_extreme" = "Linear Decreasing (Extreme)"
)

for (i in seq_along(scenarios_to_include)) {
  scenario <- scenarios_to_include[i]
  
  methods <- names(summary_stats_scenarios[[scenario]])
  
  scenario_label <- ifelse(scenario %in% names(scenario_labels),
                          scenario_labels[scenario],
                          scenario)
  
  plot_data <- data.frame(
    Method = factor(methods, levels = methods),
    Mean = sapply(methods, function(m) 
      summary_stats_scenarios[[scenario]][[m]][["swc_bias"]]$mean),
    CI_Lower = sapply(methods, function(m) 
      summary_stats_scenarios[[scenario]][[m]][["swc_bias"]]$ci_lower),
    CI_Upper = sapply(methods, function(m) 
      summary_stats_scenarios[[scenario]][[m]][["swc_bias"]]$ci_upper)
  )
  
  plot_data$Method <- factor(plot_data$Method, 
                            levels = method_order,
                            labels = method_labels[method_order])
  
  p <- ggplot(plot_data, aes(x = Method, y = Mean)) +
    geom_hline(yintercept = 0, linetype = "dashed", color = "red", alpha = 0.5) +
    geom_point(size = 3) +
    geom_errorbar(aes(ymin = CI_Lower, ymax = CI_Upper), width = 0.2) +
    labs(title = paste(scenario_label),
         y = "Signed Difference") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  plots_swc_list[[i]] <- p
}

grid.arrange(grobs = plots_swc_list, ncol = 4)
```
